/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Some weights of the model checkpoint at facebook/deit-base-distilled-patch16-224 were not used when initializing DeiTForImageClassificationWithTeacher: ['cls_classifier.bias', 'cls_classifier.weight', 'distillation_classifier.bias', 'distillation_classifier.weight']
- This IS expected if you are initializing DeiTForImageClassificationWithTeacher from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DeiTForImageClassificationWithTeacher from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loaded: (145, 145, 200) (145, 145)
Coords total=64 train=32 val=32
Tiles pre-filter: train=8 val=7
After rarity filter:
  train: {}
  val  : {}
Traceback (most recent call last):
  File "/home/pkadukar/furi-hsi/jobs/run_deit_t32s16_weighted_es.py", line 176, in <module>
    args = TrainingArguments(
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'
