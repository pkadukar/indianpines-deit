/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loaded: (145, 145, 200) (145, 145)
Coords total=289 train=145 val=144
Tiles pre-filter: train=116 val=121
After rarity filter:
  train: {3: 9, 12: 9, 15: 3, 11: 26, 2: 15, 14: 18, 10: 8, 8: 7, 4: 2, 6: 9, 5: 7, 1: 1, 13: 2}
  val  : {3: 7, 12: 8, 15: 3, 11: 25, 14: 21, 2: 16, 10: 9, 4: 3, 8: 6, 6: 11, 5: 8, 13: 2}
num_labels: 13
Traceback (most recent call last):
  File "/home/pkadukar/furi-hsi/jobs/run_deit_t32s16_weighted_es.py", line 254, in <module>
    model = AutoModelForImageClassification.from_pretrained(MODEL_NAME, config=config)
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5051, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/modeling_utils.py", line 5471, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/modeling_utils.py", line 847, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/modeling_utils.py", line 770, in _load_state_dict_into_meta_model
    _load_parameter_into_model(model, param_name, param.to(param_device))
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/transformers/modeling_utils.py", line 667, in _load_parameter_into_model
    module.load_state_dict({param_type: tensor}, strict=False, assign=True)
  File "/home/pkadukar/miniconda3/envs/furi310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for Linear:
	size mismatch for weight: copying a param with shape torch.Size([1000, 768]) from checkpoint, the shape in current model is torch.Size([13, 768]).
